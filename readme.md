# ğŸ› ï¸ SenaryLabTask: AI-Powered Support Ticket Classifier

A full-stack web application that enables users to submit support tickets, which are then analyzed using OpenAI's API to classify their content and assess urgency.

Built with:

- ğŸš€ **FastAPI** for the backend
- âš›ï¸ **React + Vite** for the frontend
- ğŸ§  **OpenAI GPT** for classification logic

---

## ğŸ“† Features

- Submit support tickets with attachments
- OpenAI-powered classification (category + urgency score)
- CORS-enabled backend API
- Upload and parse text input
- Store ticket and LLM response mapping
- JSON-based configuration and ticket database

---

## âš™ï¸ Setup Instructions

### ğŸ“ Prerequisites

- Python 3.10+
- Node.js + npm
- Docker & Docker Compose (optional)

---

## ğŸš€ Running the Project

There are **two ways** to run this project:

### ğŸŸ¢ Option 1: Using the Bash Script

```bash
./run_project.sh
```

This script starts both the FastAPI backend and the Vite React frontend from the project root.

### ğŸ³ Option 2: Using Docker Compose

```bash
docker compose up --build
```

This spins up both services in containers with volumes and port mappings configured.

---

## ğŸ” Environment Configuration

Before running, **you must set up your environment variables** in a `.env` file in the root directory. The file should include:

- OpenAI credentials
- Path to the config file (either `default_config.json` or `docker_config.json`)

Use `.env.example` as a template:

```env
OPENAI_API_KEY=your_api_key
OPENAI_ORG_ID=your_org_id
OPENAI_PROJECT_ID=your_project_id
CONFIG_PATH=backend/config/default_config.json  # or docker_config.json if using Docker
```

---

## ğŸ§² Running Tests

Backend unit tests are located in the `/backend/tests/` folder.

Run with:

```bash
pytest
```

---
##  Reuesting API Directly 

To send requests to Backend 

use this command template:

```curl
  curl -X POST http://localhost:8000/submit-ticket \
  -F "ticket_id=IT-ABC12345" \
  -F "first_name=name" \
  -F "last_name=lastname" \
  -F "email=name@example.com" \
  -F "phone=+971500000000" \
  -F "text= issue description"
```
## ğŸ“ Project Structure

```
SenaryLabTask/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ database/
â”‚   â””â”€â”€ tests/
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”œâ”€â”€ run_project.sh
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env.example
```

---

## âœ¨ Sample LLM Output Format

The response from the OpenAI API is expected to be in this JSON format:

```json
{
  "feedback_text": "Example text",
  "category": "Bug Report",
  "urgency_score": 3
}
```

---

## ğŸ“¢ Feedback

For questions or suggestions, feel free to open an issue or reach out.

